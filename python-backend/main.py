from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
import pandas as pd
import io
import zipfile
import os
from typing import Optional, List, Dict, Tuple
from supabase import create_client, Client
import json
import locale
import re
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote

# --- é…ç½®éƒ¨åˆ† ---
app = FastAPI(title="Excel Processing API", version="1.0.0")

# å…è®¸è·¨åŸŸè¯·æ±‚ï¼ˆè¿™æ ·ä½ çš„å‰ç«¯æ‰èƒ½è°ƒè¿™ä¸ªæ¥å£ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŠŠ * æ¢æˆä½ å‰ç«¯çš„åŸŸåï¼Œå¦‚ ["https://yourdomain.com"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¿æ¥ Supabase
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")  # å»ºè®®ä½¿ç”¨ service_role key

supabase: Optional[Client] = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ Supabase è¿æ¥å¤±è´¥: {e}")
else:
    print("âš ï¸ è­¦å‘Š: ç¯å¢ƒå˜é‡ SUPABASE_URL æˆ– SUPABASE_KEY æœªè®¾ç½®")

# --- æ ¸å¿ƒé€»è¾‘ ---
@app.post("/process")
async def process_excel(
    file: UploadFile = File(...),
    service_id: Optional[str] = Form(None),
    input_text: Optional[str] = Form(None)
):
    """
    å¤„ç†ä¸Šä¼ çš„ Excel/ZIP æ–‡ä»¶
    
    å‚æ•°:
    - file: ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒ .xlsx, .xls, .zipï¼‰
    - service_id: å¯é€‰çš„æœåŠ¡IDï¼ˆç”¨äºè®°å½•ï¼‰
    - input_text: å¯é€‰çš„æ–‡æœ¬è¾“å…¥
    """
    # âœ… ä¿®å¤ï¼šå®‰å…¨å¤„ç†æ–‡ä»¶åï¼ˆå¯èƒ½åŒ…å«é ASCII å­—ç¬¦ï¼‰
    original_filename = file.filename or "uploaded_file"
    try:
        # å°è¯•è§£ç æ–‡ä»¶åï¼ˆå¦‚æœæ˜¯ä» HTTP header æ¥çš„ï¼Œå¯èƒ½æ˜¯ URL ç¼–ç çš„ï¼‰
        if isinstance(original_filename, bytes):
            original_filename = original_filename.decode('utf-8', errors='replace')
    except:
        pass
    
    print(f"ğŸ“¥ æ”¶åˆ°æ–‡ä»¶: {original_filename}, ç±»å‹: {file.content_type}")
    print(f"ğŸ”‘ Service ID: {service_id}")
    print(f"ğŸ“ Input Text: {input_text}")
    
    try:
        # 1. è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
        content = await file.read()
        file_extension = os.path.splitext(original_filename)[1].lower()
        
        df = None
        result_filename = None
        
        # 2. æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
        if file_extension == '.zip':
            # å¤„ç† ZIP æ–‡ä»¶
            if not zipfile.is_zipfile(io.BytesIO(content)):
                raise HTTPException(status_code=400, detail="ä¸Šä¼ çš„ä¸æ˜¯æœ‰æ•ˆçš„ ZIP æ–‡ä»¶")
            
            input_zip = zipfile.ZipFile(io.BytesIO(content))
            file_list = input_zip.namelist()
            
            # å¯»æ‰¾ç›®æ ‡æ–‡ä»¶ï¼ˆå¯ä»¥æ ¹æ® service_id æˆ–æ–‡ä»¶åæ¨¡å¼åŒ¹é…ï¼‰
            target_file = None
            if service_id == "h10" or "h10" in original_filename.lower():
                # æŸ¥æ‰¾åŒ…å« H10 çš„ Excel æ–‡ä»¶
                target_file = next((f for f in file_list if "H10" in f.upper() and (f.endswith(".xlsx") or f.endswith(".xls"))), None)
            else:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª Excel æ–‡ä»¶
                target_file = next((f for f in file_list if f.endswith((".xlsx", ".xls"))), None)
            
            if not target_file:
                raise HTTPException(status_code=400, detail=f"å‹ç¼©åŒ…é‡Œæ²¡æ‰¾åˆ° Excel æ–‡ä»¶ã€‚æ–‡ä»¶åˆ—è¡¨: {file_list}")
            
            print(f"ğŸ“‚ æ‰¾åˆ°ç›®æ ‡æ–‡ä»¶: {target_file}")
            
            # è¯»å– Excel
            with input_zip.open(target_file) as f:
                df = pd.read_excel(f)
            
            result_filename = f"processed_{os.path.splitext(target_file)[0]}.xlsx"
            
        elif file_extension in ['.xlsx', '.xls']:
            # ç›´æ¥å¤„ç† Excel æ–‡ä»¶
            df = pd.read_excel(io.BytesIO(content))
            # âœ… ä¿®å¤ï¼šå®‰å…¨å¤„ç†æ–‡ä»¶åï¼Œé¿å…ç¼–ç é—®é¢˜
            base_name = os.path.splitext(original_filename)[0]
            # å¦‚æœæ–‡ä»¶ååŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨å®‰å…¨çš„æ–‡ä»¶å
            try:
                base_name.encode('ascii')
                result_filename = f"processed_{base_name}.xlsx"
            except UnicodeEncodeError:
                # åŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºæ–‡ä»¶å
                result_filename = f"processed_result_{int(pd.Timestamp.now().timestamp() * 1000)}.xlsx"
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}ã€‚æ”¯æŒ: .xlsx, .xls, .zip")
        
        if df is None or df.empty:
            raise HTTPException(status_code=400, detail="è¯»å–çš„ Excel æ–‡ä»¶ä¸ºç©º")
        
        
        # 3. ä¸šåŠ¡é€»è¾‘å¤„ç†ï¼ˆæ ¹æ® service_id æ‰§è¡Œä¸åŒçš„å¤„ç†ï¼‰
        result = process_dataframe(df, service_id, input_text)
        
        # 4. æ£€æŸ¥è¿”å›ç±»å‹ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆæ–‡æœ¬æŠ¥å‘Šï¼‰ï¼Œè¿”å›çº¯æ–‡æœ¬æ–‡ä»¶ï¼›å¦åˆ™è¿”å› Excel
        if isinstance(result, str):
            # è¿”å›çº¯æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰
            text_bytes = result.encode('utf-8')
            return StreamingResponse(
                io.BytesIO(text_bytes),
                media_type="text/plain; charset=utf-8",
                headers={
                    "Content-Disposition": f'attachment; filename="roi_report_{int(pd.Timestamp.now().timestamp() * 1000)}.txt"'
                }
            )
        
        # 5. å¯¼å‡ºç»“æœåˆ°å†…å­˜ï¼ˆExcel æ–‡ä»¶ï¼‰
        output = io.BytesIO()
        result.to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        
        # 6. è¿”å›æ–‡ä»¶æµï¼ˆç›´æ¥ä¸‹è½½ï¼Œä¸ç»è¿‡ Supabaseï¼‰
        # âœ… ä¿®å¤ï¼šå¤„ç†ä¸­æ–‡æ–‡ä»¶åç¼–ç é—®é¢˜
        # ä½¿ç”¨ RFC 5987 æ ¼å¼æ”¯æŒ UTF-8 ç¼–ç çš„æ–‡ä»¶å
        from urllib.parse import quote
        
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼ˆå¦‚æœåŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨ URL ç¼–ç ï¼‰
        try:
            # å°è¯•ä½¿ç”¨ ASCII ç¼–ç 
            result_filename.encode('ascii')
            # æ–‡ä»¶ååªåŒ…å« ASCII å­—ç¬¦ï¼Œç›´æ¥ä½¿ç”¨
            content_disposition = f'attachment; filename="{result_filename}"'
        except UnicodeEncodeError:
            # åŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨ RFC 5987 æ ¼å¼
            # ç”Ÿæˆä¸€ä¸ª ASCII å®‰å…¨çš„ fallback æ–‡ä»¶å
            safe_ascii_filename = f"result_{int(pd.Timestamp.now().timestamp() * 1000)}.xlsx"
            # URL ç¼–ç åŸå§‹æ–‡ä»¶åç”¨äº UTF-8 ç‰ˆæœ¬
            encoded_filename = quote(result_filename, safe='')
            # ä½¿ç”¨ RFC 5987 æ ¼å¼ï¼šfilename æ˜¯ ASCII fallbackï¼Œfilename* æ˜¯ UTF-8 ç‰ˆæœ¬
            content_disposition = f'attachment; filename="{safe_ascii_filename}"; filename*=UTF-8\'\'{encoded_filename}'
        
        return StreamingResponse(
            io.BytesIO(output.getvalue()),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={
                "Content-Disposition": content_disposition
            }
        )
        
    except HTTPException:
        raise
    except ValueError as e:
        # ValueError é€šå¸¸æ˜¯ä¸šåŠ¡é€»è¾‘é”™è¯¯ï¼ˆå¦‚æ‰¾ä¸åˆ°åˆ—ï¼‰ï¼Œè¿”å› 400
        print(f"âŒ ä¸šåŠ¡é€»è¾‘é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")


def process_dataframe(df: pd.DataFrame, service_id: Optional[str], input_text: Optional[str]):
    """
    æ ¹æ®æœåŠ¡IDæ‰§è¡Œä¸åŒçš„æ•°æ®å¤„ç†é€»è¾‘
    
    è¿”å›:
    - å¦‚æœæ˜¯æ–‡æœ¬æŠ¥å‘ŠæœåŠ¡ï¼Œè¿”å› str
    - å¦‚æœæ˜¯æ–‡ä»¶å¤„ç†æœåŠ¡ï¼Œè¿”å› pd.DataFrame
    """
    result_df = df.copy()
    
    # æ ¹æ®ä¸åŒçš„ service_id æ‰§è¡Œä¸åŒçš„å¤„ç†
    if service_id == "h10" or service_id == "abfaf85c-9553-4d7b-9416-e3aff65e8587":  # Exå¤§å)
        # âœ… Exå¤§å å¤„ç†é€»è¾‘ï¼šè®¡ç®— 50ä¸ªè¯„è®ºä»¥å†…çš„ASINå æ¯”
        result_df = calculate_asin_ratio(df)
        
    elif service_id == "d144da99-d3e6-4b78-9cd5-70b1e4ced346":  # ç­›é€‰æ ¸å¿ƒå…³é”®è¯
        # âœ… ç­›é€‰æ ¸å¿ƒå…³é”®è¯é€»è¾‘
        result_df = filter_core_keywords(result_df)
        
    elif service_id == "65bb6f50-5087-488e-8f1b-350d4ed9fe00":  # è®¡ç®—æŠ•äº§æ¯”
        # âœ… è®¡ç®—æŠ•äº§æ¯”é€»è¾‘ï¼ˆè¿”å›æ–‡æœ¬æŠ¥å‘Šï¼‰
        return calculate_roi(df)
        
    else:
        # é»˜è®¤å¤„ç†
        result_df["å¤„ç†çŠ¶æ€"] = "å·²å¤„ç†"
    
    return result_df


def find_column(df: pd.DataFrame, possible_names: list, column_index: Optional[int] = None) -> Optional[str]:
    """
    æŸ¥æ‰¾åˆ—åï¼Œæ”¯æŒå¤šç§å¯èƒ½çš„åç§°æˆ–åˆ—ç´¢å¼•
    
    å‚æ•°:
    - df: DataFrame
    - possible_names: å¯èƒ½çš„åˆ—ååˆ—è¡¨ï¼ˆå¦‚ ["å…³é”®è¯", "A"]ï¼‰
    - column_index: åˆ—ç´¢å¼•ï¼ˆå¦‚ 0 è¡¨ç¤ºç¬¬1åˆ—ï¼Œ6 è¡¨ç¤ºç¬¬7åˆ—ï¼‰
    
    è¿”å›:
    - æ‰¾åˆ°çš„åˆ—åï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    # å…ˆå°è¯•æŒ‰åˆ—åæŸ¥æ‰¾
    for name in possible_names:
        if name in df.columns:
            return name
    
    # å¦‚æœæŒ‡å®šäº†åˆ—ç´¢å¼•ï¼Œå°è¯•ä½¿ç”¨ç´¢å¼•
    if column_index is not None and column_index < len(df.columns):
        return df.columns[column_index]
    
    return None


def parse_numeric(value) -> Optional[float]:
    """
    å°è¯•å°†å€¼è§£æä¸ºæ•°å€¼
    
    è¿”å›:
    - å¦‚æœæˆåŠŸè§£æä¸ºæ•°å€¼ï¼Œè¿”å› float
    - å¦‚æœæ— æ³•è§£æï¼Œè¿”å› None
    """
    if pd.isna(value):
        return None
    
    try:
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæ•°å€¼
        return float(value)
    except (ValueError, TypeError):
        # å°è¯•æ¸…ç†å­—ç¬¦ä¸²åè½¬æ¢ï¼ˆç§»é™¤ç©ºæ ¼ã€é€—å·ç­‰ï¼‰
        try:
            cleaned = str(value).strip().replace(',', '').replace('ï¼Œ', '')
            return float(cleaned)
        except (ValueError, TypeError):
            return None


def filter_core_keywords(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç­›é€‰æ ¸å¿ƒå…³é”®è¯
    
    é€»è¾‘ï¼š
    1. æ‰¾åˆ°å…³é”®è¯åˆ—ã€ç›¸å…³äº§å“åˆ—ã€ABAå‘¨æ’ååˆ—
    2. æŒ‰"ç›¸å…³äº§å“"åˆ—é™åºæ’åºï¼ˆæ•°å€¼ä¼˜å…ˆï¼Œæ— æ³•è§£æçš„è§†ä¸ºæœ€å°å€¼ï¼‰
    3. åˆ é™¤"ABAå‘¨æ’å"ä¸ºç©ºæˆ–æ— æ•ˆçš„è¡Œ
    4. å–å‰60è¡Œ
    5. åªä¿ç•™å…³é”®è¯åˆ—
    """
    # 1. æ‰¾åˆ°æ‰€éœ€çš„åˆ—
    keyword_col = find_column(df, ["å…³é”®è¯", "A"], 0)  # ç¬¬1åˆ—ï¼ˆç´¢å¼•0ï¼‰
    related_product_col = find_column(df, ["ç›¸å…³äº§å“", "G"], 6)  # ç¬¬7åˆ—ï¼ˆç´¢å¼•6ï¼‰
    aba_rank_col = find_column(df, ["ABAå‘¨æ’å", "ABAå‘¨æ’å", "I"], 8)  # ç¬¬9åˆ—ï¼ˆç´¢å¼•8ï¼‰
    
    if not keyword_col:
        raise ValueError("æœªæ‰¾åˆ°å…³é”®è¯åˆ—ï¼ˆå…³é”®è¯ æˆ– Aåˆ—ï¼‰")
    if not related_product_col:
        raise ValueError("æœªæ‰¾åˆ°ç›¸å…³äº§å“åˆ—ï¼ˆç›¸å…³äº§å“ æˆ– Gåˆ—ï¼‰")
    if not aba_rank_col:
        raise ValueError("æœªæ‰¾åˆ°ABAå‘¨æ’ååˆ—ï¼ˆABAå‘¨æ’å æˆ– Iåˆ—ï¼‰")
    
    # 2. æŒ‰"ç›¸å…³äº§å“"åˆ—è¿›è¡Œé™åºæ’åº
    # ç­–ç•¥ï¼šåˆ†ç¦»æ•°å€¼å’Œéæ•°å€¼ï¼Œåˆ†åˆ«æ’åºååˆå¹¶
    # åˆ›å»ºè¾…åŠ©åˆ—ï¼šæ ‡è¯†æ˜¯å¦ä¸ºæ•°å€¼
    df['_is_numeric'] = df[related_product_col].apply(lambda x: parse_numeric(x) is not None)
    df['_numeric_val'] = df[related_product_col].apply(lambda x: parse_numeric(x) if parse_numeric(x) is not None else float('-inf'))
    df['_str_val'] = df[related_product_col].astype(str).str.strip()
    
    # åˆ†ç¦»æ•°å€¼å’Œéæ•°å€¼è¡Œ
    numeric_rows = df[df['_is_numeric']].copy()
    non_numeric_rows = df[~df['_is_numeric']].copy()
    
    # å¯¹æ•°å€¼è¡ŒæŒ‰æ•°å€¼é™åºæ’åº
    if len(numeric_rows) > 0:
        numeric_rows = numeric_rows.sort_values('_numeric_val', ascending=False)
    
    # å¯¹éæ•°å€¼è¡ŒæŒ‰å­—ç¬¦ä¸²é™åºæ’åº
    if len(non_numeric_rows) > 0:
        # ä½¿ç”¨å­—ç¬¦ä¸²æ¯”è¾ƒå®ç°é™åºï¼ˆç®€å•æ–¹æ³•ï¼šåè½¬å­—ç¬¦ä¸²åå‡åºæ’åºï¼Œå†åè½¬å›æ¥ï¼‰
        # æˆ–è€…ç›´æ¥ä½¿ç”¨è´Ÿçš„ Unicode ç ç‚¹å€¼
        non_numeric_rows['_str_sort_key'] = non_numeric_rows['_str_val'].apply(
            lambda x: tuple(-ord(c) for c in x[:10]) if x else (float('inf'),)
        )
        non_numeric_rows = non_numeric_rows.sort_values('_str_sort_key', ascending=True).drop('_str_sort_key', axis=1)
    
    # åˆå¹¶ï¼šæ•°å€¼è¡Œåœ¨å‰ï¼Œéæ•°å€¼è¡Œåœ¨å
    df = pd.concat([numeric_rows, non_numeric_rows], ignore_index=True)
    
    # æ¸…ç†è¾…åŠ©åˆ—
    df = df.drop(['_is_numeric', '_numeric_val', '_str_val'], axis=1)
    
    # 3. åˆ é™¤"ABAå‘¨æ’å"ä¸ºç©ºæˆ–æ— æ•ˆçš„è¡Œ
    invalid_values = ['-', 'â€”', 'NA', 'N/A', 'null', 'NULL', 'Null', '']
    
    def is_valid_aba_rank(value) -> bool:
        """åˆ¤æ–­ABAå‘¨æ’åæ˜¯å¦æœ‰æ•ˆ"""
        if pd.isna(value):
            return False
        
        value_str = str(value).strip()
        if not value_str:
            return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ•ˆå€¼ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
        if value_str.upper() in [v.upper() for v in invalid_values]:
            return False
        
        return True
    
    # è¿‡æ»¤æ— æ•ˆè¡Œ
    mask = df[aba_rank_col].apply(is_valid_aba_rank)
    df = df[mask].copy()
    
    # 4. å–å‰60è¡Œ
    df = df.head(60)
    
    # 5. åªä¿ç•™å…³é”®è¯åˆ—
    result_df = df[[keyword_col]].copy()
    
    # é‡å‘½ååˆ—ä¸º"å…³é”®è¯"ï¼ˆç»Ÿä¸€è¾“å‡ºæ ¼å¼ï¼‰
    result_df.columns = ['å…³é”®è¯']
    
    return result_df


def clean_numeric_value(value) -> float:
    """
    æ¸…æ´—æ•°å€¼ï¼šå»é™¤é€—å·ï¼Œè½¬æ¢ä¸ºæ•°å€¼ï¼Œæ— æ³•è§£æçš„æŒ‰ 0 å¤„ç†
    """
    if pd.isna(value):
        return 0.0
    
    try:
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå»é™¤é€—å·å’Œå…¶ä»–åˆ†éš”ç¬¦
        value_str = str(value).strip().replace(',', '').replace('ï¼Œ', '').replace(' ', '')
        # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        return float(value_str)
    except (ValueError, TypeError):
        return 0.0


def calculate_roi(df: pd.DataFrame):
    """
    è®¡ç®—æŠ•äº§æ¯”ï¼ˆROIï¼‰
    
    é€»è¾‘ï¼š
    1. è¯»å– Excel æ•°æ®å¹¶é€è¡Œéå†
    2. å¯¹å­—æ®µè¿›è¡Œæ•°å€¼æ¸…æ´—ï¼ˆå»é™¤é€—å·ï¼Œè½¬æ¢ä¸ºæ•°å€¼ï¼Œæ— æ³•è§£æçš„æŒ‰ 0 å¤„ç†ï¼‰
    3. ç´¯åŠ è®¡ç®—å…¨è¡¨æ•°æ®ï¼ˆæ€»ç‚¹å‡»é‡ã€æ€»è´­ä¹°é‡ï¼‰
    4. è®¡ç®—åŠ æƒç«ä»·åˆ†å­
    5. è¯»å–ç¬¬ä¸€ä¸ªå¤§äº 0 çš„äº§å“å‡ä»·ä½œä¸ºå‚è€ƒå®¢å•ä»·
    6. é˜²æ­¢é™¤ä»¥ 0
    7. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ï¼ˆå¹³å‡è½¬åŒ–ç‡ã€åŠ æƒå¹³å‡ç«ä»·ã€é¢„ä¼° ACOSï¼‰
    8. æ•´ç†ä¸ºæ–‡æœ¬åˆ†ææŠ¥å‘Š
    """
    # 1. æ‰¾åˆ°æ‰€éœ€çš„åˆ—ï¼ˆæ ¹æ® n8n é€»è¾‘ï¼‰
    click_col = find_column(df, ["å‘¨ç‚¹å‡»é‡", "E"], 4)  # Eåˆ—ï¼ˆç´¢å¼•4ï¼Œç¬¬5åˆ—ï¼‰
    purchase_col = find_column(df, ["å‘¨è´­ä¹°é‡", "F"], 5)  # Fåˆ—ï¼ˆç´¢å¼•5ï¼Œç¬¬6åˆ—ï¼‰
    bid_col = find_column(df, ["PPCç«ä»·-æœ€é«˜($)", "PPCç«ä»·-ä¸­ä½($)", "ç«ä»·-æ¨è", "ç«ä»·", "K"], 10)  # Kåˆ—ï¼ˆç´¢å¼•10ï¼Œç¬¬11åˆ—ï¼‰
    price_col = find_column(df, ["äº§å“å‡ä»·-å¹³å‡($)", "å‡ä»·-å¹³å‡", "äº§å“å‡ä»·", "å®¢å•ä»·", "R"], 17)  # Råˆ—ï¼ˆç´¢å¼•17ï¼Œç¬¬18åˆ—ï¼‰
    
    if not click_col:
        raise ValueError("æœªæ‰¾åˆ°å‘¨ç‚¹å‡»é‡åˆ—")
    if not purchase_col:
        raise ValueError("æœªæ‰¾åˆ°å‘¨è´­ä¹°é‡åˆ—")
    if not bid_col:
        raise ValueError("æœªæ‰¾åˆ°ç«ä»·åˆ—")
    if not price_col:
        raise ValueError("æœªæ‰¾åˆ°äº§å“å‡ä»·åˆ—")
    
    # 2. é€è¡Œéå†å¹¶æ¸…æ´—æ•°æ®
    total_clicks = 0.0
    total_purchases = 0.0
    weighted_bid_sum = 0.0  # åŠ æƒç«ä»·åˆ†å­ï¼šç«ä»· Ã— ç‚¹å‡»é‡ çš„ç´¯åŠ 
    reference_price = 0.0  # ç¬¬ä¸€ä¸ªå¤§äº 0 çš„äº§å“å‡ä»·
    
    for idx, row in df.iterrows():
        # æ¸…æ´—æ•°å€¼
        clicks = clean_numeric_value(row[click_col])
        purchases = clean_numeric_value(row[purchase_col])
        bid = clean_numeric_value(row[bid_col])
        price = clean_numeric_value(row[price_col])
        
        # ç´¯åŠ æ€»ç‚¹å‡»é‡å’Œæ€»è´­ä¹°é‡
        total_clicks += clicks
        total_purchases += purchases
        
        # è®¡ç®—åŠ æƒç«ä»·åˆ†å­ï¼ˆå½“ç‚¹å‡»é‡ > 0 ä¸”ç«ä»· > 0 æ—¶ï¼‰
        if clicks > 0 and bid > 0:
            weighted_bid_sum += bid * clicks
        
        # è¯»å–ç¬¬ä¸€ä¸ªå¤§äº 0 çš„äº§å“å‡ä»·ä½œä¸ºå‚è€ƒå®¢å•ä»·
        if reference_price == 0.0 and price > 0:
            reference_price = price
    
    # 3. é˜²æ­¢é™¤ä»¥ 0
    if total_clicks == 0:
        total_clicks = 1.0
    if reference_price == 0.0:
        reference_price = 1.0
    
    # 4. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
    # å¹³å‡è½¬åŒ–ç‡ (%) = (æ€»è´­ä¹°é‡ Ã· æ€»ç‚¹å‡»é‡) Ã— 100
    conversion_rate = (total_purchases / total_clicks) * 100
    
    # åŠ æƒå¹³å‡ç«ä»· = (ç«ä»· Ã— ç‚¹å‡»é‡ä¹‹å’Œ) Ã· æ€»ç‚¹å‡»é‡
    weighted_avg_bid = weighted_bid_sum / total_clicks
    
    # é¢„ä¼° ACOS (%) = åŠ æƒå¹³å‡ç«ä»· Ã· (å®¢å•ä»· Ã— è½¬åŒ–ç‡) Ã— 100
    # æ³¨æ„ï¼šè½¬åŒ–ç‡éœ€è¦è½¬æ¢ä¸ºå°æ•°ï¼ˆé™¤ä»¥ 100ï¼‰
    if conversion_rate > 0:
        estimated_acos = (weighted_avg_bid / (reference_price * (conversion_rate / 100))) * 100
    else:
        estimated_acos = 0.0
    
    # 5. æ•´ç†ä¸ºæ–‡æœ¬åˆ†ææŠ¥å‘Šï¼ˆæ ¹æ® n8n é€»è¾‘æ ¼å¼ï¼‰
    report = f"""ğŸ“Š å–å®¶ç²¾çµå…³é”®è¯åˆ†ææŠ¥å‘Š

ğŸ”¹ æ•°æ®è¡Œæ•°: {len(df)} è¡Œ
ğŸ”¹ æ€»ç‚¹å‡»é‡: {total_clicks:,.0f} æ¬¡
ğŸ”¹ æ€»è´­ä¹°é‡: {total_purchases:,.0f} å•
ğŸ”¹ å‚è€ƒå®¢å•ä»·: ${reference_price:.2f}

ğŸ“ˆ å¹³å‡ç‚¹å‡»è½¬åŒ–ç‡: {conversion_rate:.2f}%
ğŸ’° åŠ æƒå¹³å‡å»ºè®®ç«ä»·: ${weighted_avg_bid:.2f}"""
    
    if conversion_rate == 0:
        report += f"\nğŸ“‰ é¢„ä¼°æ€» ACOS: æ— æ³•è®¡ç®— (æ— è½¬åŒ–)"
    else:
        report += f"\nğŸ“‰ é¢„ä¼°æ€» ACOS: {estimated_acos:.2f}%"
    
    return report


def search_amazon_natural_products(keyword: str, max_retries: int = 3) -> List[Dict[str, any]]:
    """
    åœ¨ Amazon ç¾å›½ç«™æœç´¢å…³é”®è¯ï¼Œè·å–é¦–é¡µè‡ªç„¶ä½ ASIN åŠå…¶è¯„è®ºæ•°
    å‚è€ƒ n8n é€»è¾‘ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ‡åˆ† HTML å—å¹¶è§£æ
    
    å‚æ•°:
    - keyword: æœç´¢å…³é”®è¯
    - max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    è¿”å›:
    - List[Dict]: æ¯ä¸ªå…ƒç´ åŒ…å« {'asin': 'B0XXX', 'ratingCount': 123} æˆ–ç©ºåˆ—è¡¨ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    """
    url = f"https://www.amazon.com/s?k={quote(keyword)}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    for attempt in range(max_retries):
        try:
            # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¢«åçˆ¬è™«
            if attempt > 0:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’ã€8ç§’
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # è·å– HTML æ–‡æœ¬ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼‰
            html = response.text
            
            # Step 1ï¸âƒ£ï¼šåˆ‡åˆ†æœç´¢ç»“æœå—ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼‰
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ‡åˆ†åŒ…å« data-component-type="s-search-result" çš„ div
            blocks = re.split(r'<div[^>]+data-component-type="s-search-result"[^>]*>', html, flags=re.IGNORECASE)
            blocks = blocks[1:]  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå—ï¼ˆåˆ‡åˆ†å‰çš„éƒ¨åˆ†ï¼‰
            
            items = []
            
            # Step 2ï¸âƒ£ï¼šå¾ªç¯è§£æ ASIN + è¯„è®ºæ•°ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼‰
            for raw in blocks:
                # æå– ASINï¼ˆ10ä½å­—æ¯æ•°å­—ï¼‰
                asin_match = re.search(r'data-asin="([A-Z0-9]{10})"', raw, re.IGNORECASE)
                if not asin_match:
                    continue
                
                asin = asin_match.group(1)
                
                # è·³è¿‡å¹¿å‘Šï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼šæ£€æµ‹å¤šä¸ªå¹¿å‘Šæ ‡è¯†ï¼‰
                is_sponsored = bool(re.search(
                    r'sp-sponsored-result|AdHolder|SponsoredAd|aria-label="Sponsored"|>Sponsored<',
                    raw,
                    re.IGNORECASE
                ))
                if is_sponsored:
                    continue
                
                # æå–è¯„è®ºæ•°ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨ aria-labelï¼Œå…¶æ¬¡ä½¿ç”¨ >æ•°å­— ratings</a>ï¼‰
                rating_match = (
                    re.search(r'aria-label="([\d,]+)\s+ratings?"', raw, re.IGNORECASE) or
                    re.search(r'>\s*([\d,]+)\s+ratings?\s*</a>', raw, re.IGNORECASE)
                )
                
                rating_count = 0
                if rating_match:
                    try:
                        rating_count = int(rating_match.group(1).replace(',', ''))
                    except (ValueError, AttributeError):
                        rating_count = 0
                
                items.append({
                    'asin': asin,
                    'ratingCount': rating_count
                })
            
            # å¦‚æœæ‰¾åˆ°äº†äº§å“ï¼Œè¿”å›ç»“æœ
            if items:
                print(f"  âœ… æ‰¾åˆ° {len(items)} ä¸ªè‡ªç„¶ä½äº§å“")
                return items
            else:
                print(f"  âš ï¸ æœªæ‰¾åˆ°ä»»ä½•äº§å“")
                return []
            
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ Amazon æœç´¢è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
            if attempt == max_retries - 1:
                print(f"âŒ æ— æ³•è·å–å…³é”®è¯ '{keyword}' çš„æœç´¢ç»“æœ")
                return []
        except Exception as e:
            print(f"âš ï¸ è§£æ Amazon æœç´¢ç»“æœå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
            if attempt == max_retries - 1:
                print(f"âŒ æ— æ³•è§£æå…³é”®è¯ '{keyword}' çš„æœç´¢ç»“æœ")
                import traceback
                traceback.print_exc()
                return []
    
    return []


def calculate_asin_ratio(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®— 50ä¸ªè¯„è®ºä»¥å†…çš„ASINå æ¯”
    
    é€»è¾‘ï¼š
    1. æ‰¾åˆ°"å…³é”®è¯"åˆ—ï¼ˆä½œä¸ºä¸»é”®ï¼‰
    2. å¯¹æ¯ä¸€è¡Œå…³é”®è¯ï¼Œåœ¨ Amazon æœç´¢å¹¶è·å–é¦–é¡µè‡ªç„¶ä½ ASIN
    3. ç»Ÿè®¡é¦–é¡µè‡ªç„¶ä½ ASIN æ€»æ•°
    4. ç­›é€‰è¯„è®ºæ•° < 50 çš„ ASIN
    5. è®¡ç®—å æ¯”
    6. åœ¨åŸè¡¨ä¸­æ’å…¥æ–°åˆ—"50ä¸ªè¯„è®ºä»¥å†…çš„ASINå æ¯”"
    """
    # 1. æ‰¾åˆ°"å…³é”®è¯"åˆ—
    keyword_col = find_column(df, ["å…³é”®è¯", "å…³é”®è¯åˆ—", "Keyword", "A"], 0)
    
    if not keyword_col:
        raise ValueError("æœªæ‰¾åˆ°'å…³é”®è¯'åˆ—ï¼Œè¯·ç¡®ä¿ Excel æ–‡ä»¶åŒ…å«'å…³é”®è¯'åˆ—")
    
    # 2. åˆ›å»ºç»“æœ DataFrameï¼ˆå¤åˆ¶åŸè¡¨ï¼‰
    result_df = df.copy()
    
    # 3. ç¡®å®šæ–°åˆ—çš„æ’å…¥ä½ç½®ï¼ˆå…³é”®è¯åˆ—çš„å³ä¾§ï¼Œå³ç´¢å¼• +1ï¼‰
    keyword_col_index = list(result_df.columns).index(keyword_col)
    new_col_name = "50ä¸ªè¯„è®ºä»¥å†…çš„ASINå æ¯”"
    
    # 4. åˆå§‹åŒ–æ–°åˆ—
    result_df[new_col_name] = "0.00%"
    
    # 5. é€è¡Œå¤„ç†å…³é”®è¯
    total_rows = len(result_df)
    print(f"ğŸ“Š å¼€å§‹å¤„ç† {total_rows} ä¸ªå…³é”®è¯...")
    
    for idx, row in result_df.iterrows():
        keyword = str(row[keyword_col]).strip()
        
        if not keyword or keyword == 'nan' or keyword == '':
            print(f"âš ï¸ ç¬¬ {idx + 1} è¡Œï¼šå…³é”®è¯ä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        print(f"ğŸ” [{idx + 1}/{total_rows}] å¤„ç†å…³é”®è¯: {keyword}")
        
        try:
            # æœç´¢ Amazon è·å–é¦–é¡µè‡ªç„¶ä½ ASIN
            products = search_amazon_natural_products(keyword)
            
            if not products:
                print(f"  âš ï¸ æœªæ‰¾åˆ°æœç´¢ç»“æœï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.00%")
                result_df.at[idx, new_col_name] = "0.00%"
                # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1)
                continue
            
            # Step 1ï¸âƒ£ è¿‡æ»¤ Sponsored å¹¿å‘Šå—ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼šäºŒæ¬¡è¿‡æ»¤ï¼‰
            # æ³¨æ„ï¼šsearch_amazon_natural_products å·²ç»è¿‡æ»¤äº†å¤§éƒ¨åˆ†å¹¿å‘Šï¼Œè¿™é‡Œä¿ç•™æ‰€æœ‰
            filtered = products  # å·²ç»è¿‡æ»¤è¿‡äº†
            
            # Step 2ï¸âƒ£ æ‰¾å‡ºè¯„è®ºæ•°ä½äº 50 çš„è‡ªç„¶ä½ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼‰
            low_ratings = [p for p in filtered if p['ratingCount'] < 50]
            
            # Step 3ï¸âƒ£ è®¡ç®—å æ¯”ï¼ˆå‚è€ƒ n8n é€»è¾‘ï¼‰
            # åˆ†å­ï¼šä½è¯„è®ºæ•°ï¼ˆ<50ï¼‰çš„è‡ªç„¶ä½äº§å“æ•°é‡
            numerator = len(low_ratings)
            # åˆ†æ¯ï¼šå»é™¤å¹¿å‘Šåé¦–é¡µè‡ªç„¶ä½æ€»æ•°
            denominator = len(filtered)
            
            # è®¡ç®—å æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼Œä¿ç•™ 2 ä½å°æ•°ï¼Œå‚è€ƒ n8n é€»è¾‘ï¼‰
            if denominator > 0:
                ratio = (numerator / denominator) * 100
                ratio_percent = f"{ratio:.2f}%"
            else:
                ratio_percent = "0.00%"
            
            result_df.at[idx, new_col_name] = ratio_percent
            print(f"  âœ… å®Œæˆï¼šæ€»ASIN={denominator}, ä½è¯„è®ºASIN={numerator}, å æ¯”={ratio_percent}")
            
            # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«ï¼ˆæ¯ä¸ªå…³é”®è¯ä¹‹é—´å»¶è¿Ÿ 2 ç§’ï¼‰
            time.sleep(2)
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {str(e)}")
            result_df.at[idx, new_col_name] = "0.00%"
            import traceback
            traceback.print_exc()
            # å³ä½¿å‡ºé”™ä¹Ÿæ·»åŠ å»¶è¿Ÿ
            time.sleep(1)
    
    # 6. å°†æ–°åˆ—æ’å…¥åˆ°å…³é”®è¯åˆ—çš„å³ä¾§
    cols = list(result_df.columns)
    cols.remove(new_col_name)
    insert_index = keyword_col_index + 1
    cols.insert(insert_index, new_col_name)
    result_df = result_df[cols]
    
    print(f"âœ… å¤„ç†å®Œæˆï¼Œå·²æ·»åŠ æ–°åˆ— '{new_col_name}'")
    return result_df


@app.post("/webhook/{webhook_path:path}")
async def webhook_handler(
    webhook_path: str,
    file: Optional[UploadFile] = File(None),
    data: Optional[str] = Form(None)
):
    """
    å…¼å®¹ n8n webhook æ ¼å¼çš„æ¥å£
    æ”¯æŒé€šè¿‡è·¯å¾„åŒºåˆ†ä¸åŒçš„æœåŠ¡
    """
    # æ ¹æ® webhook_path æ˜ å°„åˆ° service_id
    path_mapping = {
        "h10": "abfaf85c-9553-4d7b-9416-e3aff65e8587",
        "test-hook": "d144da99-d3e6-4b78-9cd5-70b1e4ced346",
        "d6898f17-a3dd-4171-9a74-24e5cbe67e16": "65bb6f50-5087-488e-8f1b-350d4ed9fe00",
    }
    
    service_id = path_mapping.get(webhook_path)
    input_text = None
    
    if data:
        try:
            data_dict = json.loads(data)
            input_text = data_dict.get("input_text")
        except:
            input_text = data
    
    if file:
        return await process_excel(file=file, service_id=service_id, input_text=input_text)
    else:
        raise HTTPException(status_code=400, detail="éœ€è¦ä¸Šä¼ æ–‡ä»¶")


@app.get("/")
def read_root():
    return {
        "status": "running",
        "message": "Python Backend is Running!",
        "endpoints": {
            "/process": "å¤„ç† Excel æ–‡ä»¶",
            "/webhook/{path}": "Webhook æ¥å£ï¼ˆå…¼å®¹ n8nï¼‰",
            "/docs": "API æ–‡æ¡£"
        }
    }


@app.get("/health")
def health_check():
    return {"status": "healthy", "supabase_connected": supabase is not None}

