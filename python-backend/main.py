from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
import pandas as pd
import io
import zipfile
import os
from typing import Optional
from supabase import create_client, Client
import json
import locale
import re

# --- é…ç½®éƒ¨åˆ† ---
app = FastAPI(title="Excel Processing API", version="1.0.0")

# å…è®¸è·¨åŸŸè¯·æ±‚ï¼ˆè¿™æ ·ä½ çš„å‰ç«¯æ‰èƒ½è°ƒè¿™ä¸ªæ¥å£ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŠŠ * æ¢æˆä½ å‰ç«¯çš„åŸŸåï¼Œå¦‚ ["https://yourdomain.com"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¿æ¥ Supabase
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")  # å»ºè®®ä½¿ç”¨ service_role key

supabase: Optional[Client] = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ Supabase è¿æ¥å¤±è´¥: {e}")
else:
    print("âš ï¸ è­¦å‘Š: ç¯å¢ƒå˜é‡ SUPABASE_URL æˆ– SUPABASE_KEY æœªè®¾ç½®")

# --- æ ¸å¿ƒé€»è¾‘ ---
@app.post("/process")
async def process_excel(
    file: UploadFile = File(...),
    service_id: Optional[str] = Form(None),
    input_text: Optional[str] = Form(None)
):
    """
    å¤„ç†ä¸Šä¼ çš„ Excel/ZIP æ–‡ä»¶
    
    å‚æ•°:
    - file: ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒ .xlsx, .xls, .zipï¼‰
    - service_id: å¯é€‰çš„æœåŠ¡IDï¼ˆç”¨äºè®°å½•ï¼‰
    - input_text: å¯é€‰çš„æ–‡æœ¬è¾“å…¥
    """
    # âœ… ä¿®å¤ï¼šå®‰å…¨å¤„ç†æ–‡ä»¶åï¼ˆå¯èƒ½åŒ…å«é ASCII å­—ç¬¦ï¼‰
    original_filename = file.filename or "uploaded_file"
    try:
        # å°è¯•è§£ç æ–‡ä»¶åï¼ˆå¦‚æœæ˜¯ä» HTTP header æ¥çš„ï¼Œå¯èƒ½æ˜¯ URL ç¼–ç çš„ï¼‰
        if isinstance(original_filename, bytes):
            original_filename = original_filename.decode('utf-8', errors='replace')
    except:
        pass
    
    print(f"ğŸ“¥ æ”¶åˆ°æ–‡ä»¶: {original_filename}, ç±»å‹: {file.content_type}")
    print(f"ğŸ”‘ Service ID: {service_id}")
    print(f"ğŸ“ Input Text: {input_text}")
    
    try:
        # 1. è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
        content = await file.read()
        file_extension = os.path.splitext(original_filename)[1].lower()
        
        df = None
        result_filename = None
        
        # 2. æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
        if file_extension == '.zip':
            # å¤„ç† ZIP æ–‡ä»¶
            if not zipfile.is_zipfile(io.BytesIO(content)):
                raise HTTPException(status_code=400, detail="ä¸Šä¼ çš„ä¸æ˜¯æœ‰æ•ˆçš„ ZIP æ–‡ä»¶")
            
            input_zip = zipfile.ZipFile(io.BytesIO(content))
            file_list = input_zip.namelist()
            
            # å¯»æ‰¾ç›®æ ‡æ–‡ä»¶ï¼ˆå¯ä»¥æ ¹æ® service_id æˆ–æ–‡ä»¶åæ¨¡å¼åŒ¹é…ï¼‰
            target_file = None
            if service_id == "h10" or "h10" in original_filename.lower():
                # æŸ¥æ‰¾åŒ…å« H10 çš„ Excel æ–‡ä»¶
                target_file = next((f for f in file_list if "H10" in f.upper() and (f.endswith(".xlsx") or f.endswith(".xls"))), None)
            else:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª Excel æ–‡ä»¶
                target_file = next((f for f in file_list if f.endswith((".xlsx", ".xls"))), None)
            
            if not target_file:
                raise HTTPException(status_code=400, detail=f"å‹ç¼©åŒ…é‡Œæ²¡æ‰¾åˆ° Excel æ–‡ä»¶ã€‚æ–‡ä»¶åˆ—è¡¨: {file_list}")
            
            print(f"ğŸ“‚ æ‰¾åˆ°ç›®æ ‡æ–‡ä»¶: {target_file}")
            
            # è¯»å– Excel
            with input_zip.open(target_file) as f:
                df = pd.read_excel(f)
            
            result_filename = f"processed_{os.path.splitext(target_file)[0]}.xlsx"
            
        elif file_extension in ['.xlsx', '.xls']:
            # ç›´æ¥å¤„ç† Excel æ–‡ä»¶
            df = pd.read_excel(io.BytesIO(content))
            # âœ… ä¿®å¤ï¼šå®‰å…¨å¤„ç†æ–‡ä»¶åï¼Œé¿å…ç¼–ç é—®é¢˜
            base_name = os.path.splitext(original_filename)[0]
            # å¦‚æœæ–‡ä»¶ååŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨å®‰å…¨çš„æ–‡ä»¶å
            try:
                base_name.encode('ascii')
                result_filename = f"processed_{base_name}.xlsx"
            except UnicodeEncodeError:
                # åŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºæ–‡ä»¶å
                result_filename = f"processed_result_{int(pd.Timestamp.now().timestamp() * 1000)}.xlsx"
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}ã€‚æ”¯æŒ: .xlsx, .xls, .zip")
        
        if df is None or df.empty:
            raise HTTPException(status_code=400, detail="è¯»å–çš„ Excel æ–‡ä»¶ä¸ºç©º")
        
        
        # 3. ä¸šåŠ¡é€»è¾‘å¤„ç†ï¼ˆæ ¹æ® service_id æ‰§è¡Œä¸åŒçš„å¤„ç†ï¼‰
        result = process_dataframe(df, service_id, input_text)
        
        # 4. æ£€æŸ¥è¿”å›ç±»å‹ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆæ–‡æœ¬æŠ¥å‘Šï¼‰ï¼Œè¿”å›çº¯æ–‡æœ¬æ–‡ä»¶ï¼›å¦åˆ™è¿”å› Excel
        if isinstance(result, str):
            # è¿”å›çº¯æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰
            text_bytes = result.encode('utf-8')
            return StreamingResponse(
                io.BytesIO(text_bytes),
                media_type="text/plain; charset=utf-8",
                headers={
                    "Content-Disposition": f'attachment; filename="roi_report_{int(pd.Timestamp.now().timestamp() * 1000)}.txt"'
                }
            )
        
        # 5. å¯¼å‡ºç»“æœåˆ°å†…å­˜ï¼ˆExcel æ–‡ä»¶ï¼‰
        output = io.BytesIO()
        result.to_excel(output, index=False, engine='openpyxl')
        output.seek(0)
        
        # 6. è¿”å›æ–‡ä»¶æµï¼ˆç›´æ¥ä¸‹è½½ï¼Œä¸ç»è¿‡ Supabaseï¼‰
        # âœ… ä¿®å¤ï¼šå¤„ç†ä¸­æ–‡æ–‡ä»¶åç¼–ç é—®é¢˜
        # ä½¿ç”¨ RFC 5987 æ ¼å¼æ”¯æŒ UTF-8 ç¼–ç çš„æ–‡ä»¶å
        from urllib.parse import quote
        
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼ˆå¦‚æœåŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨ URL ç¼–ç ï¼‰
        try:
            # å°è¯•ä½¿ç”¨ ASCII ç¼–ç 
            result_filename.encode('ascii')
            # æ–‡ä»¶ååªåŒ…å« ASCII å­—ç¬¦ï¼Œç›´æ¥ä½¿ç”¨
            content_disposition = f'attachment; filename="{result_filename}"'
        except UnicodeEncodeError:
            # åŒ…å«é ASCII å­—ç¬¦ï¼Œä½¿ç”¨ RFC 5987 æ ¼å¼
            # ç”Ÿæˆä¸€ä¸ª ASCII å®‰å…¨çš„ fallback æ–‡ä»¶å
            safe_ascii_filename = f"result_{int(pd.Timestamp.now().timestamp() * 1000)}.xlsx"
            # URL ç¼–ç åŸå§‹æ–‡ä»¶åç”¨äº UTF-8 ç‰ˆæœ¬
            encoded_filename = quote(result_filename, safe='')
            # ä½¿ç”¨ RFC 5987 æ ¼å¼ï¼šfilename æ˜¯ ASCII fallbackï¼Œfilename* æ˜¯ UTF-8 ç‰ˆæœ¬
            content_disposition = f'attachment; filename="{safe_ascii_filename}"; filename*=UTF-8\'\'{encoded_filename}'
        
        return StreamingResponse(
            io.BytesIO(output.getvalue()),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={
                "Content-Disposition": content_disposition
            }
        )
        
    except HTTPException:
        raise
    except ValueError as e:
        # ValueError é€šå¸¸æ˜¯ä¸šåŠ¡é€»è¾‘é”™è¯¯ï¼ˆå¦‚æ‰¾ä¸åˆ°åˆ—ï¼‰ï¼Œè¿”å› 400
        print(f"âŒ ä¸šåŠ¡é€»è¾‘é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")


def process_dataframe(df: pd.DataFrame, service_id: Optional[str], input_text: Optional[str]):
    """
    æ ¹æ®æœåŠ¡IDæ‰§è¡Œä¸åŒçš„æ•°æ®å¤„ç†é€»è¾‘
    
    è¿”å›:
    - å¦‚æœæ˜¯æ–‡æœ¬æŠ¥å‘ŠæœåŠ¡ï¼Œè¿”å› str
    - å¦‚æœæ˜¯æ–‡ä»¶å¤„ç†æœåŠ¡ï¼Œè¿”å› pd.DataFrame
    """
    result_df = df.copy()
    
    # æ ¹æ®ä¸åŒçš„ service_id æ‰§è¡Œä¸åŒçš„å¤„ç†
    if service_id == "h10" or service_id == "abfaf85c-9553-4d7b-9416-e3aff65e8587":  # Exå¤§å)
        # H10 å¤„ç†é€»è¾‘
        # ç¤ºä¾‹ï¼šæ·»åŠ å¤„ç†çŠ¶æ€åˆ—
        result_df["å¤„ç†çŠ¶æ€"] = "å·²é€šè¿‡ Python åç«¯å¤„ç†"
        result_df["å¤„ç†æ—¶é—´"] = pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä½ çš„å…·ä½“ä¸šåŠ¡é€»è¾‘
        
    elif service_id == "d144da99-d3e6-4b78-9cd5-70b1e4ced346":  # ç­›é€‰æ ¸å¿ƒå…³é”®è¯
        # âœ… ç­›é€‰æ ¸å¿ƒå…³é”®è¯é€»è¾‘
        result_df = filter_core_keywords(result_df)
        
    elif service_id == "65bb6f50-5087-488e-8f1b-350d4ed9fe00":  # è®¡ç®—æŠ•äº§æ¯”
        # âœ… è®¡ç®—æŠ•äº§æ¯”é€»è¾‘ï¼ˆè¿”å›æ–‡æœ¬æŠ¥å‘Šï¼‰
        return calculate_roi(df)
        
    else:
        # é»˜è®¤å¤„ç†
        result_df["å¤„ç†çŠ¶æ€"] = "å·²å¤„ç†"
    
    return result_df


def find_column(df: pd.DataFrame, possible_names: list, column_index: Optional[int] = None) -> Optional[str]:
    """
    æŸ¥æ‰¾åˆ—åï¼Œæ”¯æŒå¤šç§å¯èƒ½çš„åç§°æˆ–åˆ—ç´¢å¼•
    
    å‚æ•°:
    - df: DataFrame
    - possible_names: å¯èƒ½çš„åˆ—ååˆ—è¡¨ï¼ˆå¦‚ ["å…³é”®è¯", "A"]ï¼‰
    - column_index: åˆ—ç´¢å¼•ï¼ˆå¦‚ 0 è¡¨ç¤ºç¬¬1åˆ—ï¼Œ6 è¡¨ç¤ºç¬¬7åˆ—ï¼‰
    
    è¿”å›:
    - æ‰¾åˆ°çš„åˆ—åï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    # å…ˆå°è¯•æŒ‰åˆ—åæŸ¥æ‰¾
    for name in possible_names:
        if name in df.columns:
            return name
    
    # å¦‚æœæŒ‡å®šäº†åˆ—ç´¢å¼•ï¼Œå°è¯•ä½¿ç”¨ç´¢å¼•
    if column_index is not None and column_index < len(df.columns):
        return df.columns[column_index]
    
    return None


def parse_numeric(value) -> Optional[float]:
    """
    å°è¯•å°†å€¼è§£æä¸ºæ•°å€¼
    
    è¿”å›:
    - å¦‚æœæˆåŠŸè§£æä¸ºæ•°å€¼ï¼Œè¿”å› float
    - å¦‚æœæ— æ³•è§£æï¼Œè¿”å› None
    """
    if pd.isna(value):
        return None
    
    try:
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæ•°å€¼
        return float(value)
    except (ValueError, TypeError):
        # å°è¯•æ¸…ç†å­—ç¬¦ä¸²åè½¬æ¢ï¼ˆç§»é™¤ç©ºæ ¼ã€é€—å·ç­‰ï¼‰
        try:
            cleaned = str(value).strip().replace(',', '').replace('ï¼Œ', '')
            return float(cleaned)
        except (ValueError, TypeError):
            return None


def filter_core_keywords(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç­›é€‰æ ¸å¿ƒå…³é”®è¯
    
    é€»è¾‘ï¼š
    1. æ‰¾åˆ°å…³é”®è¯åˆ—ã€ç›¸å…³äº§å“åˆ—ã€ABAå‘¨æ’ååˆ—
    2. æŒ‰"ç›¸å…³äº§å“"åˆ—é™åºæ’åºï¼ˆæ•°å€¼ä¼˜å…ˆï¼Œæ— æ³•è§£æçš„è§†ä¸ºæœ€å°å€¼ï¼‰
    3. åˆ é™¤"ABAå‘¨æ’å"ä¸ºç©ºæˆ–æ— æ•ˆçš„è¡Œ
    4. å–å‰60è¡Œ
    5. åªä¿ç•™å…³é”®è¯åˆ—
    """
    # 1. æ‰¾åˆ°æ‰€éœ€çš„åˆ—
    keyword_col = find_column(df, ["å…³é”®è¯", "A"], 0)  # ç¬¬1åˆ—ï¼ˆç´¢å¼•0ï¼‰
    related_product_col = find_column(df, ["ç›¸å…³äº§å“", "G"], 6)  # ç¬¬7åˆ—ï¼ˆç´¢å¼•6ï¼‰
    aba_rank_col = find_column(df, ["ABAå‘¨æ’å", "ABAå‘¨æ’å", "I"], 8)  # ç¬¬9åˆ—ï¼ˆç´¢å¼•8ï¼‰
    
    if not keyword_col:
        raise ValueError("æœªæ‰¾åˆ°å…³é”®è¯åˆ—ï¼ˆå…³é”®è¯ æˆ– Aåˆ—ï¼‰")
    if not related_product_col:
        raise ValueError("æœªæ‰¾åˆ°ç›¸å…³äº§å“åˆ—ï¼ˆç›¸å…³äº§å“ æˆ– Gåˆ—ï¼‰")
    if not aba_rank_col:
        raise ValueError("æœªæ‰¾åˆ°ABAå‘¨æ’ååˆ—ï¼ˆABAå‘¨æ’å æˆ– Iåˆ—ï¼‰")
    
    # 2. æŒ‰"ç›¸å…³äº§å“"åˆ—è¿›è¡Œé™åºæ’åº
    # ç­–ç•¥ï¼šåˆ†ç¦»æ•°å€¼å’Œéæ•°å€¼ï¼Œåˆ†åˆ«æ’åºååˆå¹¶
    # åˆ›å»ºè¾…åŠ©åˆ—ï¼šæ ‡è¯†æ˜¯å¦ä¸ºæ•°å€¼
    df['_is_numeric'] = df[related_product_col].apply(lambda x: parse_numeric(x) is not None)
    df['_numeric_val'] = df[related_product_col].apply(lambda x: parse_numeric(x) if parse_numeric(x) is not None else float('-inf'))
    df['_str_val'] = df[related_product_col].astype(str).str.strip()
    
    # åˆ†ç¦»æ•°å€¼å’Œéæ•°å€¼è¡Œ
    numeric_rows = df[df['_is_numeric']].copy()
    non_numeric_rows = df[~df['_is_numeric']].copy()
    
    # å¯¹æ•°å€¼è¡ŒæŒ‰æ•°å€¼é™åºæ’åº
    if len(numeric_rows) > 0:
        numeric_rows = numeric_rows.sort_values('_numeric_val', ascending=False)
    
    # å¯¹éæ•°å€¼è¡ŒæŒ‰å­—ç¬¦ä¸²é™åºæ’åº
    if len(non_numeric_rows) > 0:
        # ä½¿ç”¨å­—ç¬¦ä¸²æ¯”è¾ƒå®ç°é™åºï¼ˆç®€å•æ–¹æ³•ï¼šåè½¬å­—ç¬¦ä¸²åå‡åºæ’åºï¼Œå†åè½¬å›æ¥ï¼‰
        # æˆ–è€…ç›´æ¥ä½¿ç”¨è´Ÿçš„ Unicode ç ç‚¹å€¼
        non_numeric_rows['_str_sort_key'] = non_numeric_rows['_str_val'].apply(
            lambda x: tuple(-ord(c) for c in x[:10]) if x else (float('inf'),)
        )
        non_numeric_rows = non_numeric_rows.sort_values('_str_sort_key', ascending=True).drop('_str_sort_key', axis=1)
    
    # åˆå¹¶ï¼šæ•°å€¼è¡Œåœ¨å‰ï¼Œéæ•°å€¼è¡Œåœ¨å
    df = pd.concat([numeric_rows, non_numeric_rows], ignore_index=True)
    
    # æ¸…ç†è¾…åŠ©åˆ—
    df = df.drop(['_is_numeric', '_numeric_val', '_str_val'], axis=1)
    
    # 3. åˆ é™¤"ABAå‘¨æ’å"ä¸ºç©ºæˆ–æ— æ•ˆçš„è¡Œ
    invalid_values = ['-', 'â€”', 'NA', 'N/A', 'null', 'NULL', 'Null', '']
    
    def is_valid_aba_rank(value) -> bool:
        """åˆ¤æ–­ABAå‘¨æ’åæ˜¯å¦æœ‰æ•ˆ"""
        if pd.isna(value):
            return False
        
        value_str = str(value).strip()
        if not value_str:
            return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ•ˆå€¼ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
        if value_str.upper() in [v.upper() for v in invalid_values]:
            return False
        
        return True
    
    # è¿‡æ»¤æ— æ•ˆè¡Œ
    mask = df[aba_rank_col].apply(is_valid_aba_rank)
    df = df[mask].copy()
    
    # 4. å–å‰60è¡Œ
    df = df.head(60)
    
    # 5. åªä¿ç•™å…³é”®è¯åˆ—
    result_df = df[[keyword_col]].copy()
    
    # é‡å‘½ååˆ—ä¸º"å…³é”®è¯"ï¼ˆç»Ÿä¸€è¾“å‡ºæ ¼å¼ï¼‰
    result_df.columns = ['å…³é”®è¯']
    
    return result_df


def clean_numeric_value(value) -> float:
    """
    æ¸…æ´—æ•°å€¼ï¼šå»é™¤é€—å·ï¼Œè½¬æ¢ä¸ºæ•°å€¼ï¼Œæ— æ³•è§£æçš„æŒ‰ 0 å¤„ç†
    """
    if pd.isna(value):
        return 0.0
    
    try:
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå»é™¤é€—å·å’Œå…¶ä»–åˆ†éš”ç¬¦
        value_str = str(value).strip().replace(',', '').replace('ï¼Œ', '').replace(' ', '')
        # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        return float(value_str)
    except (ValueError, TypeError):
        return 0.0


def calculate_roi(df: pd.DataFrame):
    """
    è®¡ç®—æŠ•äº§æ¯”ï¼ˆROIï¼‰
    
    é€»è¾‘ï¼š
    1. è¯»å– Excel æ•°æ®å¹¶é€è¡Œéå†
    2. å¯¹å­—æ®µè¿›è¡Œæ•°å€¼æ¸…æ´—ï¼ˆå»é™¤é€—å·ï¼Œè½¬æ¢ä¸ºæ•°å€¼ï¼Œæ— æ³•è§£æçš„æŒ‰ 0 å¤„ç†ï¼‰
    3. ç´¯åŠ è®¡ç®—å…¨è¡¨æ•°æ®ï¼ˆæ€»ç‚¹å‡»é‡ã€æ€»è´­ä¹°é‡ï¼‰
    4. è®¡ç®—åŠ æƒç«ä»·åˆ†å­
    5. è¯»å–ç¬¬ä¸€ä¸ªå¤§äº 0 çš„äº§å“å‡ä»·ä½œä¸ºå‚è€ƒå®¢å•ä»·
    6. é˜²æ­¢é™¤ä»¥ 0
    7. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ï¼ˆå¹³å‡è½¬åŒ–ç‡ã€åŠ æƒå¹³å‡ç«ä»·ã€é¢„ä¼° ACOSï¼‰
    8. æ•´ç†ä¸ºæ–‡æœ¬åˆ†ææŠ¥å‘Š
    """
    # 1. æ‰¾åˆ°æ‰€éœ€çš„åˆ—
    click_col = find_column(df, ["å‘¨ç‚¹å‡»é‡", "ç‚¹å‡»é‡", "Clicks"], 5)  # Fåˆ—ï¼ˆç´¢å¼•5ï¼‰
    purchase_col = find_column(df, ["å‘¨è´­ä¹°é‡", "è´­ä¹°é‡", "Purchases"], 6)  # Gåˆ—ï¼ˆç´¢å¼•6ï¼‰
    bid_col = find_column(df, ["ç«ä»·-æ¨è", "ç«ä»·", "Bid", "å‡ºä»·"], 10)  # Kåˆ—ï¼ˆç´¢å¼•10ï¼‰
    price_col = find_column(df, ["å‡ä»·-å¹³å‡", "äº§å“å‡ä»·", "å®¢å•ä»·", "Price", "å¹³å‡ä»·æ ¼"], 15)  # Påˆ—ï¼ˆç´¢å¼•15ï¼‰
    
    if not click_col:
        raise ValueError("æœªæ‰¾åˆ°å‘¨ç‚¹å‡»é‡åˆ—")
    if not purchase_col:
        raise ValueError("æœªæ‰¾åˆ°å‘¨è´­ä¹°é‡åˆ—")
    if not bid_col:
        raise ValueError("æœªæ‰¾åˆ°ç«ä»·åˆ—")
    if not price_col:
        raise ValueError("æœªæ‰¾åˆ°äº§å“å‡ä»·åˆ—")
    
    # 2. é€è¡Œéå†å¹¶æ¸…æ´—æ•°æ®
    total_clicks = 0.0
    total_purchases = 0.0
    weighted_bid_sum = 0.0  # åŠ æƒç«ä»·åˆ†å­ï¼šç«ä»· Ã— ç‚¹å‡»é‡ çš„ç´¯åŠ 
    reference_price = 0.0  # ç¬¬ä¸€ä¸ªå¤§äº 0 çš„äº§å“å‡ä»·
    
    for idx, row in df.iterrows():
        # æ¸…æ´—æ•°å€¼
        clicks = clean_numeric_value(row[click_col])
        purchases = clean_numeric_value(row[purchase_col])
        bid = clean_numeric_value(row[bid_col])
        price = clean_numeric_value(row[price_col])
        
        # ç´¯åŠ æ€»ç‚¹å‡»é‡å’Œæ€»è´­ä¹°é‡
        total_clicks += clicks
        total_purchases += purchases
        
        # è®¡ç®—åŠ æƒç«ä»·åˆ†å­ï¼ˆå½“ç‚¹å‡»é‡ > 0 ä¸”ç«ä»· > 0 æ—¶ï¼‰
        if clicks > 0 and bid > 0:
            weighted_bid_sum += bid * clicks
        
        # è¯»å–ç¬¬ä¸€ä¸ªå¤§äº 0 çš„äº§å“å‡ä»·ä½œä¸ºå‚è€ƒå®¢å•ä»·
        if reference_price == 0.0 and price > 0:
            reference_price = price
    
    # 3. é˜²æ­¢é™¤ä»¥ 0
    if total_clicks == 0:
        total_clicks = 1.0
    if reference_price == 0.0:
        reference_price = 1.0
    
    # 4. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
    # å¹³å‡è½¬åŒ–ç‡ (%) = (æ€»è´­ä¹°é‡ Ã· æ€»ç‚¹å‡»é‡) Ã— 100
    conversion_rate = (total_purchases / total_clicks) * 100
    
    # åŠ æƒå¹³å‡ç«ä»· = (ç«ä»· Ã— ç‚¹å‡»é‡ä¹‹å’Œ) Ã· æ€»ç‚¹å‡»é‡
    weighted_avg_bid = weighted_bid_sum / total_clicks
    
    # é¢„ä¼° ACOS (%) = åŠ æƒå¹³å‡ç«ä»· Ã· (å®¢å•ä»· Ã— è½¬åŒ–ç‡) Ã— 100
    # æ³¨æ„ï¼šè½¬åŒ–ç‡éœ€è¦è½¬æ¢ä¸ºå°æ•°ï¼ˆé™¤ä»¥ 100ï¼‰
    if conversion_rate > 0:
        estimated_acos = (weighted_avg_bid / (reference_price * (conversion_rate / 100))) * 100
    else:
        estimated_acos = 0.0
    
    # 5. æ•´ç†ä¸ºæ–‡æœ¬åˆ†ææŠ¥å‘Šï¼ˆåªåŒ…å«æ ¸å¿ƒæŒ‡æ ‡ï¼‰
    report = f"""æŠ•äº§æ¯”åˆ†ææŠ¥å‘Š

æ ¸å¿ƒæŒ‡æ ‡ï¼š
å¹³å‡è½¬åŒ–ç‡: {conversion_rate:.2f}%
åŠ æƒå¹³å‡ç«ä»·: {weighted_avg_bid:.2f}
é¢„ä¼° ACOS: {estimated_acos:.2f}%"""
    
    return report


@app.post("/webhook/{webhook_path:path}")
async def webhook_handler(
    webhook_path: str,
    file: Optional[UploadFile] = File(None),
    data: Optional[str] = Form(None)
):
    """
    å…¼å®¹ n8n webhook æ ¼å¼çš„æ¥å£
    æ”¯æŒé€šè¿‡è·¯å¾„åŒºåˆ†ä¸åŒçš„æœåŠ¡
    """
    # æ ¹æ® webhook_path æ˜ å°„åˆ° service_id
    path_mapping = {
        "h10": "abfaf85c-9553-4d7b-9416-e3aff65e8587",
        "test-hook": "d144da99-d3e6-4b78-9cd5-70b1e4ced346",
        "d6898f17-a3dd-4171-9a74-24e5cbe67e16": "65bb6f50-5087-488e-8f1b-350d4ed9fe00",
    }
    
    service_id = path_mapping.get(webhook_path)
    input_text = None
    
    if data:
        try:
            data_dict = json.loads(data)
            input_text = data_dict.get("input_text")
        except:
            input_text = data
    
    if file:
        return await process_excel(file=file, service_id=service_id, input_text=input_text)
    else:
        raise HTTPException(status_code=400, detail="éœ€è¦ä¸Šä¼ æ–‡ä»¶")


@app.get("/")
def read_root():
    return {
        "status": "running",
        "message": "Python Backend is Running!",
        "endpoints": {
            "/process": "å¤„ç† Excel æ–‡ä»¶",
            "/webhook/{path}": "Webhook æ¥å£ï¼ˆå…¼å®¹ n8nï¼‰",
            "/docs": "API æ–‡æ¡£"
        }
    }


@app.get("/health")
def health_check():
    return {"status": "healthy", "supabase_connected": supabase is not None}

